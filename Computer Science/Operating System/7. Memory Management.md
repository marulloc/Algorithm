# Memory Management

초기 컴퓨터 시스템에서 CPU는 하나였기 때문에, 메모리 관리는 복잡할 것이 없었다. 그러나 **Multi Programming**의 등장으로 여러개의 CPU가 하나의 메모리를 같이 쓰게 되었고, 더 효율적으로 메모리를 사용하기 위해 Memory Management가 발전하기 시작했다. 초기 시스템에서는 프로그램을 메모리에 통채로 로드해야지만 실행이 가능했지만, 현재는 효과적인 관리 방법들이 등장했다.

# 효과적인 메모리 사용을 위해

1. Dynamic Loading
2. Dynamic Linking
3. Swapping

# Memory 할당 전략

1. 연속 메모리 할당
   - 고정 분할
   - 가변 분할
2. 분산 메모리 할당
   - 가상메모리
     - paging
     - segmentation
   - 그냥 Paging
   - 그냥 segmentation

# 가상메모리

- 분산 메모리 할당 기법과 함께, 프로그램이 통으로 실제 메모리에 올라와야 된다는 제약조건을 없애준다.
- 가상메모리는 실제 메모리보다 용량이 훨씬 크게 설정되어 있다. 따라서, 논리적으로 적재되어 있는 상태를, 실제 메모리에 적재되어있는 것처럼 CPU를 속임으로써, 실제 메모리 공간보다 큰 프로그램을 돌릴 수 있게 된다.
- 실제 존재하지 않는 가상의 메모리지만, 프로그램이 적재될 때, 물리메모리에 적재되는 것이 아니라, 가상메모리에 **논리적으로** 적재된다. 가상메모리에 논리적으로 적재되었다면, 실제 실행할 때는 물리메모리를 필요로하게 된다.

  - MMU가 가상메모리 상에 적재된 것을 실제 메모리로 올리는 일을 담당하고 있으며, CPU는 가상메모리의 논리주소로 동작한다.
  - MMU는 하드웨어로 구현된 반도체 칩이다. CPU과 Memory 중간에 위치하여 CPU가 속아서 사용하는 논리적 주소를 실제 메모리의 주소로 변환해준다.
  - 큰 프로그램이 실행될 때, 가상메모리에 모두 적재되어 있으나, 실제 실행되는 부분만 피지컬 메모리에 적재할 수 있게 되었다.

### 가상메모리 Paging

- page 라는 단위가 존재한다.
- 가상 메모리를 page라는 단위로 분할하고, 실제 메모리도 page란 단위로 분할해둔다.
  - page로 분할된 **실제 메모리 영역** 하나 하나를 **page frame**이라 부른다.
- 가상 메모리의 어떤 page가 실제 page frame 어느 영역에 위치해 있는지 mapping을 해둬야 하기 때문에 **PTE(페이지 테이블)**을 마련해둔다.

  - 페이지 테이블은 실제 메모리 안에 상주하게 된다.

  1. CPU가 명령어를 수행하다가 논리주소 A에 접근하려고 한다.
  2. 페이지 테이블에 접근해서 실제 주소를 구한뒤
  3. 실제 주소를 가지고 메인메모리에 접근하여 데이터를 읽거나 쓴다.

  - 따라서 메모리를 2번 접근한다. 더 최악의 경우는 커널모드를 사용할 때다.

  1. User 프로세스가 시스템콜을 호출한다.
  2. Trap에 의해 커널모드가 켜지고, 커널 함수 사용을 위해 커널의 페이지 테이블에 접근하여 실제 주소를 알아온다.
  3. 커널 페이지의 실제주소를 가지고 메인메모리에 접근한다. (만약 유저 프로세스의 주소를 건드리는 시스템 콜이라면 아래의 단계까지 나아간다.)
  4. User의 페이지 테이블에 접근하여 실제 주소를 알아온다.
  5. 실제 주소를 가지고 메인메모리에 접근한다.
  6. 커널 끝

##### pte 구성

- valid bit
  - 값이 0이면, 현재 PTE가 가리키는 frame이 없다.
  - 값이 1이면, 현재 PTE가 가리키는 frame이 있다.
- dirty bit
  - 가리키고 있는 page frame 값이 변경되었다.
  - 페이지 교체 알고리즘에 의해 페이지가 쫒겨날 때, dirty bit를보고, 변경이 되었다면, disk의 스왑스페이스로 보내고??
- access bit
  - 해당 페이지 프레임의 내용을 읽을 수 있느냐 없느냐
- PF#
  - 가상메모리의 page가 실제 메모리 몇번째 frame에 적재되어있는지 번호가 담겨있는 것

##### 그러나 가상메모리에 적재도 안된 상태라면??

디스크에서 뽑아와야한다.

##### 이렇게 반복되는 메모리 접근을 피하기 위해 TLB를 사용한다.

- 페이지 테이블으 ㅣ캐시메모리다.
- Key / value 형태로 저장되어 있음

1. CPU가 논리주소 하나를 보내면 이제 MMU가 맡아서 동작
2. MMU는 페이지 번호 P를 TLB에게 보낸다.
3. TLB에 해당 페이지가 있으면(hit), 실제 주소를 바로 알려주고, CPU는 메모리로 가서 액세스
4. Miss라면, 메인메모리의 페이지테이블에 접근한다.
   - 페이지 테이블의 Valid bit 가 1이면 실제 주소를 받아온다.
   - Valid bit가 0이면 **Page Fault** 발생 (MMU가 CPU에게 Page fault Interrupt 발생)
   - Page Falut가 발생하면 Disk I/O 시작

### Paging Policy

page가 있냐 없냐에 따라서 수행시간이 많이 차이난다. 따라서 Paging 정책을 잘 둬야한다. 고려해야 하는 paging 정책은 다음과 같다.

1. Fetch Policy : 언제 페이지를 가져올 것이냐
   - Demand Paging
   - Prepaging
2. Placement Policy : 메모리 어디에다가 적재할 것이냐
3. Replacement Policy : 언제 쫒아낼 것이냐
   - 페이지 교체 알고리즘 : FIFO, LRU
     - LRU(Least Recently Used) : 가장 중요한 페이지 교체 정책 (최근에 가장 사용되지 않은 페이지를 골라서 내보내는 것). Temporal Locality에 기반한 Page Replacement 정책. Locality(지역성) 때문임. 프로그램의 수행에 Spatial Locality가 있기 때문에 지금 사용되는 페이지들은 가까운 미래에도 사용될 것이고 최근에 사용되지 않았던 페이지들은 Temporal Locality 때문에 미래에도 사용되지 않을 것이다. https://jennysgap.tistory.com/entry/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C%EC%9D%98-%EA%B8%B0%EC%B4%88-18-Demand-Paging-2

- Working set : OS가 알아서하자.. 어떤 집합 안에 있는 페이지가 올라와야할때는, 집합 전체가 올라오고, 집합 안에 있는 한 페이지가 빠질때는, 집합 전체가 빠지자. page in/out의 오버헤드를 감소시킬 수 있음
